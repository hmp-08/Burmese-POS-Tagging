{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dde2df6",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737b3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4e2d5c",
   "metadata": {},
   "source": [
    "# Read data and substitute pipe with space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb324be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_lst =[]\n",
    "with open('mypos-ver.3.0.txt', \"r\") as file:\n",
    "    for line in file:\n",
    "        sentences = line.split(\".\")\n",
    "        modified_sentences = [sentence.replace(\"|\", \" \") for sentence in sentences]\n",
    "        modified_line = \".\".join(modified_sentences)\n",
    "        mod_lst.append(modified_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af949d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ဒီ/adj ဆေး/n က/ppm ၁၀၀/num ရာခိုင်နှုန်း/n ဆေးဘက်ဝင်/adj အပင်/n များ/part မှ/ppm ဖော်စပ်/v ထား/part တာ/part ဖြစ်/v တယ်/ppm ။/punc\\n',\n",
       " 'အသစ်/n ဝယ်/v ထား/part တဲ့/part ဆွယ်တာ/n က/ppm အသီး/n ထ/v နေ/part ပါ/part ပေါ့/part ။/punc\\n',\n",
       " 'မ/part ကျန်းမာ/v လျှင်/conj နတ်/n ဆရာ/n ထံ/ppm မေးမြန်း/v ၍/conj သက်ဆိုင်ရာ/n နတ်/n တို့/part အား/ppm ပူဇော်ပသ/v ရ/part သည်/ppm ။/punc\\n',\n",
       " 'ပေဟိုင်/n ဥယျာဉ်/n ။/punc\\n',\n",
       " 'နဝမ/adj အိပ်မက်/n ကောသလ/n မင်း/n အိပ်မက်/n ၉/num နက်ရှိုင်း/adj ကျယ်ဝန်း/adj သော/part ရေကန်/n ကြီး/adj တစ်/tn ခု/part တွင်/ppm သတ္တဝါ/n တို့/part ဆင်း/v ၍/conj ရေသောက်/v ကြ/part ၏/ppm ။/punc\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_lst[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a999d705",
   "metadata": {},
   "source": [
    "# Separate into words list and tags list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13240d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = []\n",
    "tags_list = []\n",
    "\n",
    "for item in mod_lst:\n",
    "    words = []\n",
    "    tags = []\n",
    "    pairs = item.strip().split(' ')\n",
    "    for pair in pairs: \n",
    "        if '/' in pair:\n",
    "            last_slash_index = pair.rindex('/')\n",
    "            word = pair[:last_slash_index]\n",
    "            tag = pair[last_slash_index + 1:]\n",
    "            words.append(word)\n",
    "            tags.append(tag)\n",
    "            sent_word = ' '.join([str(elem) for elem in words])\n",
    "            sent_tag = ' '.join([str(elem) for elem in tags])\n",
    "    words_list.append(sent_word)\n",
    "    tags_list.append(sent_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a6284f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ဒီ ဆေး က ၁၀၀ ရာခိုင်နှုန်း ဆေးဘက်ဝင် အပင် များ မှ ဖော်စပ် ထား တာ ဖြစ် တယ် ။',\n",
       " 'အသစ် ဝယ် ထား တဲ့ ဆွယ်တာ က အသီး ထ နေ ပါ ပေါ့ ။',\n",
       " 'မ ကျန်းမာ လျှင် နတ် ဆရာ ထံ မေးမြန်း ၍ သက်ဆိုင်ရာ နတ် တို့ အား ပူဇော်ပသ ရ သည် ။',\n",
       " 'ပေဟိုင် ဥယျာဉ် ။',\n",
       " 'နဝမ အိပ်မက် ကောသလ မင်း အိပ်မက် ၉ နက်ရှိုင်း ကျယ်ဝန်း သော ရေကန် ကြီး တစ် ခု တွင် သတ္တဝါ တို့ ဆင်း ၍ ရေသောက် ကြ ၏ ။',\n",
       " 'အပြင်ပန်း ကြည့် ရင် ခက် သလို ထင် ရ ပေမယ့် တကယ့် လက်တွေ့ အခြေအနေ က တော့ အဲဒီ လို မ ဟုတ် ပါ ဘူး ။',\n",
       " '8 bit ပုံရိပ် တစ် ခု သည် 256 color သို့မဟုတ် gray scale များ ကို အထောက်အကူ ပြု သည် ။',\n",
       " 'ကိုရီးယား ဝတ်စုံ မှာ ပန်း ဒီဇိုင်း နဲ့ အဝါရောင် က လိုက်ဖက် လိမ့် မယ် ထင် တယ် ။',\n",
       " 'သို့နှင့် မဂ္ဂဇင်း မှ တစ်ဆင့် သတင်းစာ ကို ပါ တိုးချဲ့ လိုက် သောအခါ တွင် ဘက်ပတစ် ကျောင်း သို့ မ ပြန် တော့ ဘဲ ထို မဂ္ဂဇင်း ၊ သတင်းစာ နှစ် ခု စလုံး တွင် ပင် တည်းဖြတ် သည့် ဘက် မှ ဆက်လက် လုပ်ကိုင် လေ တော့ သည် ။',\n",
       " 'တစ် ကျပ်သား ။',\n",
       " 'ညနေ ၆ နာရီ ခွဲ တိတိ ပါ ။',\n",
       " '၂ နာရီ လောက် ကြာ မယ် ။',\n",
       " 'ထို အစီအစဉ် မှာ တိုကျို တွင် အုပ်ချုပ် ရေး ဆိုင်ရာ ပညာရပ် များ ကို လေ့လာ နေ သော သခင် ထွန်းအုပ် အား ဟိုက်နန် တွင် စစ်ပညာ များ သင်ကြား နေ သည့် သခင် အောင်ဆန်း နှင့် တွေ့ဆုံ ၍ သခင် လူငယ် နှစ် ဖွဲ့ စည်းလုံး ညီညွတ် ရေး ဆွေးနွေး ကြ ရန် ဖြစ် သည် ။',\n",
       " 'လမ်းပိတ် နေ လို့ မြေအောက်ရထား စီး တာ ပို ကောင်း လိမ့် မယ် ။',\n",
       " 'မင်း စောစော က တော့ မ ပြော ဘူး ။',\n",
       " 'ကျောက်ဖရုံသီး ။',\n",
       " 'အဲ့ဒီ အခန်း ရဲ့ နောက်ဆုံး မှာ ထိုင် နေ တဲ့ သူ က ဘယ်သူ လဲ ။',\n",
       " 'ဒီ အဆောက်အဦး ထဲ မှာ ဈေးဆိုင် အမျိုးမျိုး ရှိ တယ် ။',\n",
       " 'ခင်ဗျား သူဌေး ဒီ မနက် အခြေအနေ ဘယ်လို ရှိ လဲ ။',\n",
       " 'ရှေး ခေတ် သထုံ သည် ပင်လယ် ဆိပ်ကမ်း မြို့ ဖြစ် ခဲ့ သည် ။']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64fddfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adj n ppm num n adj n part ppm v part part v ppm punc',\n",
       " 'n v part part n ppm n v part part part punc',\n",
       " 'part v conj n n ppm v conj n n part ppm v part ppm punc',\n",
       " 'n n punc',\n",
       " 'adj n n n n num adj adj part n adj tn part ppm n part v conj v part ppm punc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33beb2ac",
   "metadata": {},
   "source": [
    "# Export src and tgt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62679d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(words_list, tags_list)),columns =['words', 'tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32eb6120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ဒီ ဆေး က ၁၀၀ ရာခိုင်နှုန်း ဆေးဘက်ဝင် အပင် များ...</td>\n",
       "      <td>adj n ppm num n adj n part ppm v part part v p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>အသစ် ဝယ် ထား တဲ့ ဆွယ်တာ က အသီး ထ နေ ပါ ပေါ့ ။</td>\n",
       "      <td>n v part part n ppm n v part part part punc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>မ ကျန်းမာ လျှင် နတ် ဆရာ ထံ မေးမြန်း ၍ သက်ဆိုင်...</td>\n",
       "      <td>part v conj n n ppm v conj n n part ppm v part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ပေဟိုင် ဥယျာဉ် ။</td>\n",
       "      <td>n n punc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>နဝမ အိပ်မက် ကောသလ မင်း အိပ်မက် ၉ နက်ရှိုင်း ကျ...</td>\n",
       "      <td>adj n n n n num adj adj part n adj tn part ppm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  \\\n",
       "0  ဒီ ဆေး က ၁၀၀ ရာခိုင်နှုန်း ဆေးဘက်ဝင် အပင် များ...   \n",
       "1      အသစ် ဝယ် ထား တဲ့ ဆွယ်တာ က အသီး ထ နေ ပါ ပေါ့ ။   \n",
       "2  မ ကျန်းမာ လျှင် နတ် ဆရာ ထံ မေးမြန်း ၍ သက်ဆိုင်...   \n",
       "3                                   ပေဟိုင် ဥယျာဉ် ။   \n",
       "4  နဝမ အိပ်မက် ကောသလ မင်း အိပ်မက် ၉ နက်ရှိုင်း ကျ...   \n",
       "\n",
       "                                                tags  \n",
       "0  adj n ppm num n adj n part ppm v part part v p...  \n",
       "1        n v part part n ppm n v part part part punc  \n",
       "2  part v conj n n ppm v conj n n part ppm v part...  \n",
       "3                                           n n punc  \n",
       "4  adj n n n n num adj adj part n adj tn part ppm...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a276b33d",
   "metadata": {},
   "source": [
    "## Split train,val,test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c42423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (38876, 2)\n",
      "Validation set shape: (2160, 2)\n",
      "Test set shape: (2160, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the DataFrame into train and test sets (90% train, 10% test)\n",
    "train_df, test_df = train_test_split(df, test_size=0.10, random_state=42)\n",
    "\n",
    "# Split the test set into test and validation sets (50% test, 50% validation)\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.50, random_state=42)\n",
    "\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", val_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b8b7999",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For train\n",
    "df_words = train_df['words']\n",
    "df_words.to_csv(\"dataset/src-train.txt\",index=False,header=False)\n",
    "df_tags = train_df['tags']\n",
    "df_tags.to_csv(\"dataset/tgt-train.txt\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0509a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For val\n",
    "df_words = val_df['words']\n",
    "df_words.to_csv(\"dataset/src-val.txt\",index=False,header=False)\n",
    "df_tags = val_df['tags']\n",
    "df_tags.to_csv(\"dataset/tgt-val.txt\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbfbae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For test\n",
    "df_words = test_df['words']\n",
    "df_words.to_csv(\"dataset/src-test.txt\",index=False,header=False)\n",
    "df_tags = test_df['tags']\n",
    "df_tags.to_csv(\"dataset/tgt-test.txt\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c00bec",
   "metadata": {},
   "source": [
    "# SentencePiece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ecb3662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=dataset/src-train.txt --model_prefix=dataset/sp-src --vocab_size=10000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: dataset/src-train.txt\n",
      "  input_format: \n",
      "  model_prefix: dataset/sp-src\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 10000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: dataset/src-train.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (7208 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 38875 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 1 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=2601347\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9503% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=116\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999503\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 38875 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=1314313\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 46111 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 38875\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 23204\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 23204 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=17694 obj=9.66416 num_tokens=49764 num_tokens/piece=2.81248\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=13841 obj=8.05615 num_tokens=49864 num_tokens/piece=3.60263\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=10983 obj=8.02318 num_tokens=51272 num_tokens/piece=4.66831\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=10923 obj=7.99778 num_tokens=51280 num_tokens/piece=4.69468\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: dataset/sp-src.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: dataset/sp-src.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as sp\n",
    "\n",
    "path = 'dataset/'\n",
    "sp.SentencePieceTrainer.Train('--input=' + path + 'src-train.txt --model_prefix='+ path + 'sp-src --vocab_size=10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bf24ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=dataset/tgt-train.txt --model_prefix=dataset/sp-tgt --vocab_size=47\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: dataset/tgt-train.txt\n",
      "  input_format: \n",
      "  model_prefix: dataset/sp-tgt\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 47\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: dataset/tgt-train.txt\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 38876 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=1854844\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.953% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=16\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.99953\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 38876 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=1333035\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 53 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 38876\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 15\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 15 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=50 obj=3.59495 num_tokens=24 num_tokens/piece=0.48\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=36 obj=2.60529 num_tokens=23 num_tokens/piece=0.638889\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: dataset/sp-tgt.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: dataset/sp-tgt.vocab\n"
     ]
    }
   ],
   "source": [
    "sp.SentencePieceTrainer.Train('--input=' + path + 'tgt-train.txt --model_prefix='+ path + 'sp-tgt --vocab_size=47')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52fda5e",
   "metadata": {},
   "source": [
    "# Train Alignment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10845a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "\n",
    "path = 'dataset/'\n",
    "sp_src = spm.SentencePieceProcessor(model_file= path+ 'sp-src.model')\n",
    "sp_src_txt = []\n",
    "for sent in train_df.words:\n",
    "    text = sp_src.encode_as_pieces(sent)\n",
    "    sp_src_txt.append(\" \".join(text))\n",
    "\n",
    "sp_tgt = spm.SentencePieceProcessor(model_file= path+ 'sp-tgt.model')\n",
    "sp_tgt_txt = []\n",
    "for sent in train_df.tags:\n",
    "    text = sp_tgt.encode_as_pieces(sent)\n",
    "    sp_tgt_txt.append(\" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bbaad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_src_txt_val = []\n",
    "for sent in val_df.words:\n",
    "    text = sp_src.encode_as_pieces(sent)\n",
    "    sp_src_txt_val.append(\" \".join(text))\n",
    "    \n",
    "sp_src_txt_test = []\n",
    "for sent in test_df.words:\n",
    "    text = sp_src.encode_as_pieces(sent)\n",
    "    sp_src_txt_test.append(\" \".join(text))\n",
    "    \n",
    "sp_tgt_txt_val = []\n",
    "for sent in val_df.tags:\n",
    "    text = sp_tgt.encode_as_pieces(sent)\n",
    "    sp_tgt_txt_val.append(\" \".join(text))\n",
    "\n",
    "sp_tgt_txt_test = []\n",
    "for sent in test_df.tags:\n",
    "    text = sp_tgt.encode_as_pieces(sent)\n",
    "    sp_tgt_txt_test.append(\" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e4c8ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sp_mm'] = sp_src_txt\n",
    "train_df['sp_en'] = sp_tgt_txt\n",
    "val_df['sp_mm'] = sp_src_txt_val\n",
    "val_df['sp_en'] = sp_tgt_txt_val\n",
    "test_df['sp_mm'] = sp_src_txt_test\n",
    "test_df['sp_en'] = sp_tgt_txt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b376a3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "      <th>sp_mm</th>\n",
       "      <th>sp_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24888</th>\n",
       "      <td>ကား တစ် စီး လမ်း ညာဘက် ထောင့်ချိုး နား မှာ လူ ...</td>\n",
       "      <td>n tn n n n n part ppm n tn part ppm v part ppm...</td>\n",
       "      <td>▁ကား ▁တစ် ▁စီး ▁လမ်း ▁ညာ ဘက် ▁ထောင့် ချိုး ▁နာ...</td>\n",
       "      <td>▁n ▁ t n ▁n ▁n ▁n ▁n ▁part ▁ppm ▁n ▁ t n ▁part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21161</th>\n",
       "      <td>ကျွန် သက် ရှည် သော်လည်း မြိတ် မြို့သူ မြို့သား...</td>\n",
       "      <td>n n adj conj n n n part n v part part n adj pa...</td>\n",
       "      <td>▁ကျွန် ▁သက် ▁ရှည် ▁သော်လည်း ▁မ ြိတ် ▁မြို့သူ ▁...</td>\n",
       "      <td>▁n ▁n ▁adj ▁conj ▁n ▁n ▁n ▁part ▁n ▁v ▁part ▁p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   words  \\\n",
       "24888  ကား တစ် စီး လမ်း ညာဘက် ထောင့်ချိုး နား မှာ လူ ...   \n",
       "21161  ကျွန် သက် ရှည် သော်လည်း မြိတ် မြို့သူ မြို့သား...   \n",
       "\n",
       "                                                    tags  \\\n",
       "24888  n tn n n n n part ppm n tn part ppm v part ppm...   \n",
       "21161  n n adj conj n n n part n v part part n adj pa...   \n",
       "\n",
       "                                                   sp_mm  \\\n",
       "24888  ▁ကား ▁တစ် ▁စီး ▁လမ်း ▁ညာ ဘက် ▁ထောင့် ချိုး ▁နာ...   \n",
       "21161  ▁ကျွန် ▁သက် ▁ရှည် ▁သော်လည်း ▁မ ြိတ် ▁မြို့သူ ▁...   \n",
       "\n",
       "                                                   sp_en  \n",
       "24888  ▁n ▁ t n ▁n ▁n ▁n ▁n ▁part ▁ppm ▁n ▁ t n ▁part...  \n",
       "21161  ▁n ▁n ▁adj ▁conj ▁n ▁n ▁n ▁part ▁n ▁v ▁part ▁p...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b2e2aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "      <th>sp_mm</th>\n",
       "      <th>sp_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11098</th>\n",
       "      <td>ခင်ဗျား လာ ထိုင် ပါ ။</td>\n",
       "      <td>pron v v part punc</td>\n",
       "      <td>▁ခင်ဗျား ▁လာ ▁ထိုင် ▁ပါ ▁။</td>\n",
       "      <td>▁p r on ▁v ▁v ▁part ▁punc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>ခင်ဗျား တိုင်းပြည် အတွက် အနစ်နာခံ နိုင် မလား ။</td>\n",
       "      <td>pron n ppm v part part punc</td>\n",
       "      <td>▁ခင်ဗျား ▁ တိုင်းပြည် ▁အတွက် ▁အ နစ်နာ ခံ ▁နိုင...</td>\n",
       "      <td>▁p r on ▁n ▁ppm ▁v ▁part ▁part ▁punc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                words  \\\n",
       "11098                           ခင်ဗျား လာ ထိုင် ပါ ။   \n",
       "12788  ခင်ဗျား တိုင်းပြည် အတွက် အနစ်နာခံ နိုင် မလား ။   \n",
       "\n",
       "                              tags  \\\n",
       "11098           pron v v part punc   \n",
       "12788  pron n ppm v part part punc   \n",
       "\n",
       "                                                   sp_mm  \\\n",
       "11098                         ▁ခင်ဗျား ▁လာ ▁ထိုင် ▁ပါ ▁။   \n",
       "12788  ▁ခင်ဗျား ▁ တိုင်းပြည် ▁အတွက် ▁အ နစ်နာ ခံ ▁နိုင...   \n",
       "\n",
       "                                      sp_en  \n",
       "11098             ▁p r on ▁v ▁v ▁part ▁punc  \n",
       "12788  ▁p r on ▁n ▁ppm ▁v ▁part ▁part ▁punc  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91897811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "      <th>sp_mm</th>\n",
       "      <th>sp_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>အိန္ဒိယ သည် ဘက်မလိုက်လှုပ်ရှား မှု နှင့် ကုလသမ...</td>\n",
       "      <td>n ppm v part conj n n n n ppm v v n part ppm v...</td>\n",
       "      <td>▁အိန္ဒိယ ▁သည် ▁ဘက်မလိုက် လှုပ်ရှား ▁မှု ▁နှင့်...</td>\n",
       "      <td>▁n ▁ppm ▁v ▁part ▁conj ▁n ▁n ▁n ▁n ▁ppm ▁v ▁v ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27768</th>\n",
       "      <td>ခင်ဗျား တို့ မှာ အရွယ်အစား နည်းနည်း ကြီး တာ ရှ...</td>\n",
       "      <td>pron part ppm n adj v part v part punc</td>\n",
       "      <td>▁ခင်ဗျား ▁တို့ ▁မှာ ▁အရွယ် အစား ▁နည်းနည်း ▁ကြီ...</td>\n",
       "      <td>▁p r on ▁part ▁ppm ▁n ▁adj ▁v ▁part ▁v ▁part ▁...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   words  \\\n",
       "3861   အိန္ဒိယ သည် ဘက်မလိုက်လှုပ်ရှား မှု နှင့် ကုလသမ...   \n",
       "27768  ခင်ဗျား တို့ မှာ အရွယ်အစား နည်းနည်း ကြီး တာ ရှ...   \n",
       "\n",
       "                                                    tags  \\\n",
       "3861   n ppm v part conj n n n n ppm v v n part ppm v...   \n",
       "27768             pron part ppm n adj v part v part punc   \n",
       "\n",
       "                                                   sp_mm  \\\n",
       "3861   ▁အိန္ဒိယ ▁သည် ▁ဘက်မလိုက် လှုပ်ရှား ▁မှု ▁နှင့်...   \n",
       "27768  ▁ခင်ဗျား ▁တို့ ▁မှာ ▁အရွယ် အစား ▁နည်းနည်း ▁ကြီ...   \n",
       "\n",
       "                                                   sp_en  \n",
       "3861   ▁n ▁ppm ▁v ▁part ▁conj ▁n ▁n ▁n ▁n ▁ppm ▁v ▁v ...  \n",
       "27768  ▁p r on ▁part ▁ppm ▁n ▁adj ▁v ▁part ▁v ▁part ▁...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a055c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_alignment(src,tgt):\n",
    "    formated_sent = src + ' ||| ' + tgt\n",
    "    return formated_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c616edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9354c5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "      <th>sp_mm</th>\n",
       "      <th>sp_en</th>\n",
       "      <th>aligned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42688</th>\n",
       "      <td>ကျွန်တော် ဗိုက် အရမ်း နာ လို့ အရေးပေါ် ဆေးကုသ ဖို့ အကူအညီ အတွက် ဖုန်းဆက် ခဲ့ ရ တယ် ။</td>\n",
       "      <td>pron n adv v part n v part n ppm v part part ppm punc</td>\n",
       "      <td>▁ကျွန်တော် ▁ဗိုက် ▁အရမ်း ▁နာ ▁လို့ ▁အရေးပေါ် ▁ဆေးကုသ ▁ဖို့ ▁အကူအညီ ▁အတွက် ▁ဖုန်း ဆက် ▁ခ ဲ့ ▁ရ ▁တယ် ▁။</td>\n",
       "      <td>▁p r on ▁n ▁adv ▁v ▁part ▁n ▁v ▁part ▁n ▁ppm ▁v ▁part ▁part ▁ppm ▁punc</td>\n",
       "      <td>▁ကျွန်တော် ▁ဗိုက် ▁အရမ်း ▁နာ ▁လို့ ▁အရေးပေါ် ▁ဆေးကုသ ▁ဖို့ ▁အကူအညီ ▁အတွက် ▁ဖုန်း ဆက် ▁ခ ဲ့ ▁ရ ▁တယ် ▁။ ||| ▁p r on ▁n ▁adv ▁v ▁part ▁n ▁v ▁part ▁n ▁ppm ▁v ▁part ▁part ▁ppm ▁punc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      words  \\\n",
       "42688  ကျွန်တော် ဗိုက် အရမ်း နာ လို့ အရေးပေါ် ဆေးကုသ ဖို့ အကူအညီ အတွက် ဖုန်းဆက် ခဲ့ ရ တယ် ။   \n",
       "\n",
       "                                                        tags  \\\n",
       "42688  pron n adv v part n v part n ppm v part part ppm punc   \n",
       "\n",
       "                                                                                                       sp_mm  \\\n",
       "42688  ▁ကျွန်တော် ▁ဗိုက် ▁အရမ်း ▁နာ ▁လို့ ▁အရေးပေါ် ▁ဆေးကုသ ▁ဖို့ ▁အကူအညီ ▁အတွက် ▁ဖုန်း ဆက် ▁ခ ဲ့ ▁ရ ▁တယ် ▁။   \n",
       "\n",
       "                                                                        sp_en  \\\n",
       "42688  ▁p r on ▁n ▁adv ▁v ▁part ▁n ▁v ▁part ▁n ▁ppm ▁v ▁part ▁part ▁ppm ▁punc   \n",
       "\n",
       "                                                                                                                                                                           aligned_text  \n",
       "42688  ▁ကျွန်တော် ▁ဗိုက် ▁အရမ်း ▁နာ ▁လို့ ▁အရေးပေါ် ▁ဆေးကုသ ▁ဖို့ ▁အကူအညီ ▁အတွက် ▁ဖုန်း ဆက် ▁ခ ဲ့ ▁ရ ▁တယ် ▁။ ||| ▁p r on ▁n ▁adv ▁v ▁part ▁n ▁v ▁part ▁n ▁ppm ▁v ▁part ▁part ▁ppm ▁punc  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['aligned_text'] = train_df.apply(lambda x: format_for_alignment(x.sp_mm, x.sp_en), axis =1)\n",
    "train_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33e1f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/'\n",
    "with open(path+ 'src-tgt-aligned.txt','w') as outFile:\n",
    "    for sentences in train_df.aligned_text:\n",
    "        outFile.write(sentences + '\\n')\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55bc4337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/workspace_mt/POS\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f2949d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/workspace_mt/004_Data_Preparation/dataset/alignment/fast_align/build\n"
     ]
    }
   ],
   "source": [
    "cd /home/user/Documents/workspace_mt/004_Data_Preparation/dataset/alignment/fast_align/build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43d867ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARG=i\n",
      "ARG=d\n",
      "ARG=o\n",
      "ARG=v\n",
      "INITIAL PASS \n",
      "......................................\n",
      "expected target length = source length * 0.963195\n",
      "ITERATION 1\n",
      "......................................\n",
      "  log_e likelihood: -1.15347e+07\n",
      "  log_2 likelihood: -1.66411e+07\n",
      "     cross entropy: 29.8974\n",
      "        perplexity: 1e+09\n",
      "      posterior p0: 0.08\n",
      " posterior al-feat: -0.175416\n",
      "       size counts: 1437\n",
      "ITERATION 2\n",
      "......................................\n",
      "  log_e likelihood: -1.11438e+06\n",
      "  log_2 likelihood: -1.60771e+06\n",
      "     cross entropy: 2.8884\n",
      "        perplexity: 7.4045\n",
      "      posterior p0: 0.0665967\n",
      " posterior al-feat: -0.155348\n",
      "       size counts: 1437\n",
      "  1  model al-feat: -0.188477 (tension=4)\n",
      "  2  model al-feat: -0.171253 (tension=4.66258)\n",
      "  3  model al-feat: -0.163858 (tension=4.98068)\n",
      "  4  model al-feat: -0.160114 (tension=5.15087)\n",
      "  5  model al-feat: -0.15808 (tension=5.24619)\n",
      "  6  model al-feat: -0.156933 (tension=5.30082)\n",
      "  7  model al-feat: -0.156274 (tension=5.33251)\n",
      "  8  model al-feat: -0.155892 (tension=5.35103)\n",
      "     final tension: 5.3619\n",
      "ITERATION 3\n",
      "......................................\n",
      "  log_e likelihood: -987144\n",
      "  log_2 likelihood: -1.42415e+06\n",
      "     cross entropy: 2.55862\n",
      "        perplexity: 5.89144\n",
      "      posterior p0: 0.0598395\n",
      " posterior al-feat: -0.127049\n",
      "       size counts: 1437\n",
      "  1  model al-feat: -0.155668 (tension=5.3619)\n",
      "  2  model al-feat: -0.144615 (tension=5.93427)\n",
      "  3  model al-feat: -0.138495 (tension=6.28559)\n",
      "  4  model al-feat: -0.134753 (tension=6.5145)\n",
      "  5  model al-feat: -0.132337 (tension=6.66857)\n",
      "  6  model al-feat: -0.130725 (tension=6.77433)\n",
      "  7  model al-feat: -0.129626 (tension=6.84785)\n",
      "  8  model al-feat: -0.128866 (tension=6.89939)\n",
      "     final tension: 6.93571\n",
      "ITERATION 4\n",
      "......................................\n",
      "  log_e likelihood: -900258\n",
      "  log_2 likelihood: -1.2988e+06\n",
      "     cross entropy: 2.33341\n",
      "        perplexity: 5.03997\n",
      "      posterior p0: 0.0559854\n",
      " posterior al-feat: -0.109191\n",
      "       size counts: 1437\n",
      "  1  model al-feat: -0.128335 (tension=6.93571)\n",
      "  2  model al-feat: -0.122982 (tension=7.3186)\n",
      "  3  model al-feat: -0.119386 (tension=7.59443)\n",
      "  4  model al-feat: -0.116859 (tension=7.79834)\n",
      "  5  model al-feat: -0.115028 (tension=7.9517)\n",
      "  6  model al-feat: -0.113673 (tension=8.06844)\n",
      "  7  model al-feat: -0.112654 (tension=8.15808)\n",
      "  8  model al-feat: -0.11188 (tension=8.22735)\n",
      "     final tension: 8.28115\n",
      "ITERATION 5 (FINAL)\n",
      "......................................\n",
      "  log_e likelihood: -845187\n",
      "  log_2 likelihood: -1.21935e+06\n",
      "     cross entropy: 2.19067\n",
      "        perplexity: 4.56519\n",
      "      posterior p0: 0\n",
      " posterior al-feat: 0\n",
      "       size counts: 1437\n"
     ]
    }
   ],
   "source": [
    "!./fast_align -i /home/user/Documents/workspace_mt/POS/dataset/src-tgt-aligned.txt -d -o -v > /home/user/Documents/workspace_mt/POS/dataset/train-alignment.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5d675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt_env",
   "language": "python",
   "name": "mt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
