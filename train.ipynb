{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z_7gnGipsAj",
        "outputId": "c92d5847-d011-4b9a-8327-ce24d26eeb3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIrzV8JHqxtZ",
        "outputId": "4699090e-0939-46fc-99fe-a88adb72b4ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.10/dist-packages (20.23.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (0.3.6)\n",
            "Requirement already satisfied: filelock<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.12.0)\n",
            "Requirement already satisfied: platformdirs<4,>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install virtualenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od9HbV5Uq1_c",
        "outputId": "ecfe6dae-b4f2-423b-c945-9ae9f882f1b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created virtual environment CPython3.10.12.final.0-64 in 292ms\n",
            "  creator CPython3Posix(dest=/content/venv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==23.1.2, setuptools==67.8.0, wheel==0.40.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ],
      "source": [
        "!virtualenv venv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dI5sAYP6q7Zo"
      },
      "outputs": [],
      "source": [
        "!source venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Sn0eLFlq-fo",
        "outputId": "4d1f2221-9fc3-4d18-b4b8-8d4131033299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: OpenNMT-tf[tensorflow] in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: ctranslate2<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-tf[tensorflow]) (3.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from OpenNMT-tf[tensorflow]) (23.1)\n",
            "Requirement already satisfied: pyonmttok<2,>=1.29.0 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-tf[tensorflow]) (1.37.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-tf[tensorflow]) (6.0)\n",
            "Requirement already satisfied: rouge<2,>=1.0 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-tf[tensorflow]) (1.0.1)\n",
            "Requirement already satisfied: sacrebleu<3,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-tf[tensorflow]) (2.3.1)\n",
            "Requirement already satisfied: tensorflow-addons<0.20,>=0.16 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-tf[tensorflow]) (0.19.0)\n",
            "Requirement already satisfied: tensorflow<2.12.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-tf[tensorflow]) (2.11.1)\n",
            "Requirement already satisfied: tensorflow-text<2.12.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-tf[tensorflow]) (2.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.0->OpenNMT-tf[tensorflow]) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge<2,>=1.0->OpenNMT-tf[tensorflow]) (1.16.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3,>=1.5.0->OpenNMT-tf[tensorflow]) (2.7.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3,>=1.5.0->OpenNMT-tf[tensorflow]) (2022.10.31)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3,>=1.5.0->OpenNMT-tf[tensorflow]) (0.8.10)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3,>=1.5.0->OpenNMT-tf[tensorflow]) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3,>=1.5.0->OpenNMT-tf[tensorflow]) (4.9.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.8.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.32.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons<0.20,>=0.16->OpenNMT-tf[tensorflow]) (4.0.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.13.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install OpenNMT-tf[tensorflow]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gac_vi41ltzq",
        "outputId": "76dd22e1-5a96-4ad8-ec54-711970a07a7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WzYYemQfL8Px"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH4tWKZZMcMU",
        "outputId": "3befac75-4c9d-4086-e4be-e3f59351ecf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset\n"
          ]
        }
      ],
      "source": [
        "%cd dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vHaZhsMsmpz",
        "outputId": "68279058-4622-4a8b-b403-b090a45750e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sp-src.model  sp-tgt.vocab         src-train.txt  tgt-train.txt\n",
            "sp-src.vocab  src-test.txt         src-val.txt    tgt-val.txt\n",
            "sp-tgt.model  src-tgt-aligned.txt  tgt-test.txt   train-alignment.txt\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIQzChW8st6S",
        "outputId": "8b7391a2-8943-4c60-d87f-43b448a36c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ရောဂါ ကြောင့် တစ် ရက် နား သည် ။\n",
            "သူ က ကတိမတည် လို့ ခေါင်း တောင် မ ဖော် ရဲ ဘူး ။\n",
            "ခင်ဗျား ဘာ အစီအစဉ် ရှိ သလဲ ။\n",
            "စင်္ကာပူ ကြည်းတပ် သည် စင်္ကာပူ တပ်မတော် ၏ တပ်ဖွဲ့ ကြီး သုံး ခု အနက် အဓိက တပ်ဖွဲ့ ဖြစ် သည် ။\n",
            "ကောင်း ပါ ပြီ ၊ ဆရာ ။\n",
            "သူ များ အိမ်တွင်းရေး ကို နှိုက်နှိုက်ချွတ်ချွတ် မ မေး ပါ နဲ့ ။\n",
            "ကျွန်တော့် ရဲ့ ဝါသနာ တစ် ရပ် က ကျွန်တော့် ရဲ့ စာရေး မိတ်ဆွေ တွေ ဆီ ကို စာ များ ရေး ခြင်း ဖြစ် ပါ တယ် ။\n",
            "မိန် သည် ရာသီ ဖြစ် သည် ။\n",
            "ရထား ထဲ မှာ အရမ်း ပူ ပြီး ပြည့်ကျပ် နေ တယ် ။\n",
            "စဲန် မြစ် သည် ပါရီ ၏ မြို့ ဟောင်း ဧရိယာ ကို ပိုင်းဖြတ် ပြီး ၂ ပိုင်း ဘယ် ကမ်း နှင့် ညာ ကမ်း ခွဲ ထား သည် ။\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 src-train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmLwqv9Esylh",
        "outputId": "7ba69a4c-71bc-460a-b994-33fde940644d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n ppm tn n v ppm punc\n",
            "pron ppm v part n ppm part v part part punc\n",
            "pron adj n v part punc\n",
            "n n ppm n n ppm n part tn part ppm n n v ppm punc\n",
            "adj part ppm punc n punc\n",
            "pron part n ppm adv part v part part punc\n",
            "pron ppm n tn part ppm pron ppm v n part ppm ppm n part v part v part ppm punc\n",
            "n ppm n v ppm punc\n",
            "n ppm ppm adv v conj v part ppm punc\n",
            "n n ppm n ppm n adj n ppm v conj num part n n conj n n v part ppm punc\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 tgt-train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olgFwF6Ps5Kg",
        "outputId": "70a33124-0445-4005-f9d3-0978a6ca0042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38876 src-train.txt\n",
            "38876 tgt-train.txt\n",
            "2160 src-val.txt\n",
            "2160 tgt-val.txt\n",
            "2160 src-test.txt\n",
            "2160 tgt-test.txt\n"
          ]
        }
      ],
      "source": [
        "!wc -l src-train.txt\n",
        "!wc -l tgt-train.txt\n",
        "!wc -l src-val.txt\n",
        "!wc -l tgt-val.txt\n",
        "!wc -l src-test.txt\n",
        "!wc -l tgt-test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ4spHdRtHYX",
        "outputId": "553cb369-34f3-41dd-a038-e88bc87d8174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-22 08:16:49.359973: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-22 08:16:50.540939: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-06-22 08:16:50.541070: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-06-22 08:16:50.541107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-06-22 08:16:54.572041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-22 08:16:55.675796: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-06-22 08:16:55.675938: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-06-22 08:16:55.675961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "!onmt-build-vocab --from_vocab sp-src.vocab --from_format sentencepiece --save_vocab sp_src_vocab.txt\n",
        "!onmt-build-vocab --from_vocab sp-tgt.vocab --from_format sentencepiece --save_vocab sp_tgt_vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQy05aFFtd3V",
        "outputId": "5ae8a73f-8559-4ca1-d758-9b04d9cd24ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<blank>\n",
            "<s>\n",
            "</s>\n",
            "▁။\n",
            "▁\n",
            "▁ကို\n",
            "▁သည်\n",
            "▁ပါ\n",
            "▁တယ်\n",
            "▁က\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 sp_src_vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7lU_yqktjYG",
        "outputId": "a806d3c4-1021-43d3-efb8-fe0a3763a85b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<blank>\n",
            "<s>\n",
            "</s>\n",
            "▁part\n",
            "▁n\n",
            "▁ppm\n",
            "▁v\n",
            "▁punc\n",
            "▁p\n",
            "r\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 sp_tgt_vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhiOZ_gWtok1",
        "outputId": "0fc4e157-a300-43ba-c15e-5c6451cfb731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 sp_src_vocab.txt\n",
            "47 sp_tgt_vocab.txt\n"
          ]
        }
      ],
      "source": [
        "!wc -l sp_src_vocab.txt\n",
        "!wc -l sp_tgt_vocab.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSntzvPLtz_c"
      },
      "source": [
        "Then, the data files should be declared in a YAML configuration file, let’s name it data.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSyqfY1KuUBV",
        "outputId": "7aec6a45-f366-43a3-f2c8-0b29dc383726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-22 00:57:47.571575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-22 00:57:49.081231: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-22 00:57:49.081379: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-22 00:57:49.081409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-06-22 00:57:52.791000: I onmt-main:8] Creating model directory /content/drive/MyDrive/run/\n",
            "2023-06-22 00:57:52.930000: I main.py:315] Using OpenNMT-tf version 2.31.0\n",
            "2023-06-22 00:57:52.931000: I main.py:315] Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "2023-06-22 00:57:54.067137: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-06-22 00:57:54.071000: I main.py:325] Using parameters:\n",
            "data:\n",
            "  eval_features_file: src-val.txt\n",
            "  eval_labels_file: tgt-val.txt\n",
            "  source_tokenization:\n",
            "    params:\n",
            "      model: sp-src.model\n",
            "    type: SentencePieceTokenizer\n",
            "  source_vocabulary: sp_src_vocab.txt\n",
            "  target_tokenization:\n",
            "    params:\n",
            "      model: sp-tgt.model\n",
            "    type: SentencePieceTokenizer\n",
            "  target_vocabulary: sp_tgt_vocab.txt\n",
            "  train_alignments: train-alignment.txt\n",
            "  train_features_file: src-train.txt\n",
            "  train_labels_file: tgt-train.txt\n",
            "early_stopping:\n",
            "  metric: bleu\n",
            "  min_improvement: 0.01\n",
            "  steps: 100\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  export_format: ctranslate2\n",
            "  export_on_best: bleu\n",
            "  length_bucket_width: 5\n",
            "  max_exports_to_keep: 5\n",
            "  scorers: bleu\n",
            "  steps: 100\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/drive/MyDrive/run/\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 2.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: LazyAdam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.9\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 32\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 4\n",
            "  length_bucket_width: 2\n",
            "  max_step: 10000\n",
            "  maximum_features_length: 100\n",
            "  maximum_labels_length: 100\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 100\n",
            "  save_summary_steps: 100\n",
            "\n",
            "2023-06-22 00:57:54.277000: I inputter.py:316] Initialized source input layer:\n",
            "2023-06-22 00:57:54.277000: I inputter.py:316]  - vocabulary size: 10001\n",
            "2023-06-22 00:57:54.278000: I inputter.py:316]  - special tokens: BOS=no, EOS=no\n",
            "2023-06-22 00:57:54.284000: I inputter.py:316] Initialized target input layer:\n",
            "2023-06-22 00:57:54.284000: I inputter.py:316]  - vocabulary size: 48\n",
            "2023-06-22 00:57:54.284000: I inputter.py:316]  - special tokens: BOS=yes, EOS=yes\n",
            "2023-06-22 00:57:54.292000: W runner.py:268] No checkpoint to restore in /content/drive/MyDrive/run/\n",
            "2023-06-22 00:57:54.301000: W deprecation.py:350] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/summary/summary_iterator.py:27: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "2023-06-22 00:57:54.370000: W deprecation.py:350] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "2023-06-22 00:57:55.805000: I main.py:325] Accumulate gradients of 782 iterations to reach effective batch size of 25000\n",
            "2023-06-22 00:57:55.851000: I dataset_ops.py:2542] Training on 38876 examples\n",
            "2023-06-22 00:59:02.628000: I runner.py:309] Number of model parameters: 49310256\n",
            "2023-06-22 00:59:02.639000: I runner.py:309] Number of model weights: 260 (trainable = 260, non trainable = 0)\n",
            "2023-06-22 00:59:06.495000: I training.py:176] Saved checkpoint /content/drive/MyDrive/run/ckpt-1\n",
            "2023-06-22 01:42:10.013000: I runner.py:309] Step = 100 ; steps/s = 0.04, tokens/s = 1550 (787 source, 763 target) ; Learning rate = 0.000012 ; Loss = 2.133769\n",
            "2023-06-22 01:42:17.133000: I training.py:176] Saved checkpoint /content/drive/MyDrive/run/ckpt-100\n",
            "2023-06-22 01:42:17.133000: I training.py:192] Running evaluation for step 100\n",
            "2023-06-22 01:43:39.179000: I training.py:192] Evaluation predictions saved to /content/drive/MyDrive/run/eval/predictions.txt.100\n",
            "2023-06-22 01:43:39.569000: I training.py:192] Evaluation result for step 100: loss = 1.571307 ; perplexity = 4.812936 ; bleu = 18.495110\n",
            "2023-06-22 01:43:39.577000: I training.py:192] Exporting model to /content/drive/MyDrive/run/export/100 (best bleu so far: 18.495110)\n",
            "2023-06-22 02:27:44.577000: I runner.py:309] Step = 200 ; steps/s = 0.04, tokens/s = 1531 (777 source, 754 target) ; Learning rate = 0.000025 ; Loss = 1.918945\n",
            "2023-06-22 02:27:48.658000: I training.py:176] Saved checkpoint /content/drive/MyDrive/run/ckpt-200\n",
            "2023-06-22 02:27:48.658000: I training.py:192] Running evaluation for step 200\n",
            "2023-06-22 02:28:35.681000: I training.py:192] Evaluation predictions saved to /content/drive/MyDrive/run/eval/predictions.txt.200\n",
            "2023-06-22 02:28:36.088000: I training.py:192] Evaluation result for step 200: loss = 1.360521 ; perplexity = 3.898224 ; bleu = 25.183140\n",
            "2023-06-22 02:28:36.094000: I training.py:192] Exporting model to /content/drive/MyDrive/run/export/200 (best bleu so far: 25.183140)\n",
            "2023-06-22 03:11:47.127000: I runner.py:309] Step = 300 ; steps/s = 0.04, tokens/s = 1562 (793 source, 769 target) ; Learning rate = 0.000037 ; Loss = 1.796975\n",
            "2023-06-22 03:11:54.408000: I training.py:176] Saved checkpoint /content/drive/MyDrive/run/ckpt-300\n",
            "2023-06-22 03:11:54.409000: I training.py:192] Running evaluation for step 300\n",
            "2023-06-22 03:14:16.430000: I training.py:192] Evaluation predictions saved to /content/drive/MyDrive/run/eval/predictions.txt.300\n",
            "2023-06-22 03:14:16.647000: I training.py:192] Evaluation result for step 300: loss = 1.236578 ; perplexity = 3.443809 ; bleu = 31.608397\n",
            "2023-06-22 03:14:16.652000: I training.py:192] Exporting model to /content/drive/MyDrive/run/export/300 (best bleu so far: 31.608397)\n",
            "2023-06-22 03:57:19.510000: I runner.py:309] Step = 400 ; steps/s = 0.04, tokens/s = 1568 (796 source, 772 target) ; Learning rate = 0.000050 ; Loss = 1.671417\n",
            "2023-06-22 03:57:22.900000: I training.py:176] Saved checkpoint /content/drive/MyDrive/run/ckpt-400\n",
            "2023-06-22 03:57:22.900000: I training.py:192] Running evaluation for step 400\n",
            "2023-06-22 03:58:40.943000: I training.py:192] Evaluation predictions saved to /content/drive/MyDrive/run/eval/predictions.txt.400\n",
            "2023-06-22 03:58:41.383000: I training.py:192] Evaluation result for step 400: loss = 1.124092 ; perplexity = 3.077420 ; bleu = 38.739081\n",
            "2023-06-22 03:58:41.390000: I training.py:192] Exporting model to /content/drive/MyDrive/run/export/400 (best bleu so far: 38.739081)\n",
            "2023-06-22 04:41:36.815000: I runner.py:309] Step = 500 ; steps/s = 0.04, tokens/s = 1572 (798 source, 774 target) ; Learning rate = 0.000062 ; Loss = 1.597990\n",
            "2023-06-22 04:41:41.505000: I training.py:176] Saved checkpoint /content/drive/MyDrive/run/ckpt-500\n",
            "2023-06-22 04:41:41.506000: I training.py:192] Running evaluation for step 500\n",
            "2023-06-22 04:43:03.535000: I training.py:192] Evaluation predictions saved to /content/drive/MyDrive/run/eval/predictions.txt.500\n",
            "2023-06-22 04:43:03.801000: I training.py:192] Evaluation result for step 500: loss = 1.045775 ; perplexity = 2.845603 ; bleu = 40.068306\n",
            "2023-06-22 04:43:03.807000: I training.py:192] Exporting model to /content/drive/MyDrive/run/export/500 (best bleu so far: 40.068306)\n",
            "2023-06-22 05:26:07.987000: I runner.py:309] Step = 600 ; steps/s = 0.04, tokens/s = 1567 (795 source, 772 target) ; Learning rate = 0.000074 ; Loss = 1.495272\n",
            "2023-06-22 05:26:13.596000: I training.py:176] Saved checkpoint /content/drive/MyDrive/run/ckpt-600\n",
            "2023-06-22 05:26:13.596000: I training.py:192] Running evaluation for step 600\n",
            "2023-06-22 05:27:01.062000: I training.py:192] Evaluation predictions saved to /content/drive/MyDrive/run/eval/predictions.txt.600\n",
            "2023-06-22 05:27:01.339000: I training.py:192] Evaluation result for step 600: loss = 0.920250 ; perplexity = 2.509917 ; bleu = 47.233316\n",
            "2023-06-22 05:27:01.344000: I training.py:192] Exporting model to /content/drive/MyDrive/run/export/600 (best bleu so far: 47.233316)\n",
            "2023-06-22 06:10:04.761000: I runner.py:309] Step = 700 ; steps/s = 0.04, tokens/s = 1566 (795 source, 771 target) ; Learning rate = 0.000087 ; Loss = 1.362619\n",
            "2023-06-22 06:10:13.495000: I training.py:176] Saved checkpoint /content/drive/MyDrive/run/ckpt-700\n",
            "2023-06-22 06:10:13.495000: I training.py:192] Running evaluation for step 700\n",
            "2023-06-22 06:10:43.416000: I training.py:192] Evaluation predictions saved to /content/drive/MyDrive/run/eval/predictions.txt.700\n",
            "2023-06-22 06:10:43.882000: I training.py:192] Evaluation result for step 700: loss = 0.750320 ; perplexity = 2.117678 ; bleu = 58.355421\n",
            "2023-06-22 06:10:43.888000: I training.py:192] Exporting model to /content/drive/MyDrive/run/export/700 (best bleu so far: 58.355421)\n",
            "2023-06-22 06:53:35.852000: I runner.py:309] Step = 800 ; steps/s = 0.04, tokens/s = 1574 (799 source, 775 target) ; Learning rate = 0.000099 ; Loss = 1.266119\n",
            "2023-06-22 06:53:42.351000: I training.py:176] Saved checkpoint /content/drive/MyDrive/run/ckpt-800\n",
            "2023-06-22 06:53:42.351000: I training.py:192] Running evaluation for step 800\n",
            "2023-06-22 06:54:23.419000: I training.py:192] Evaluation predictions saved to /content/drive/MyDrive/run/eval/predictions.txt.800\n",
            "2023-06-22 06:54:23.696000: I training.py:192] Evaluation result for step 800: loss = 0.606199 ; perplexity = 1.833449 ; bleu = 66.085856\n",
            "2023-06-22 06:54:23.701000: I training.py:192] Exporting model to /content/drive/MyDrive/run/export/800 (best bleu so far: 66.085856)\n"
          ]
        }
      ],
      "source": [
        "!onmt-main --model_type Transformer --config data.yml --auto_config train --with_eval"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aRZ4bJX-NH47"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}